{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 圖像旋轉\n",
    "    >> Image Rotations\n",
    "        >> cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 仿射 變換\n",
    "    >> 簡單地 改變圖像位置的 仿射變換\n",
    "        >> 使用 cv2.warpAffine 來實現這些轉換\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('data/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# 以圍繞其中心旋轉圖像 - 除以2\n",
    "# Divide by two to rototate the image around its centre\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 圖像周圍的所有 黑色空間\n",
    "    >> 可以裁剪圖像\n",
    "    >> 因為可以計算它的新尺寸\n",
    "\n",
    "    >> 使用 cv2.transpose 函數\n",
    "        >> 進行 簡單旋轉 - cv2.transpose\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其他旋轉選項\n",
    "# Other Option to Rotate\n",
    "\n",
    "img = cv2.imread('data/input.jpg')\n",
    "\n",
    "rotated_image = cv2.transpose(img)\n",
    "\n",
    "cv2.imshow('Rotated Image - Method 2', rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 水平翻轉 -horizontaly flip.\n",
    "\n",
    "flipped = cv2.flip(image, 0)\n",
    "cv2.imshow('Horizontal Flip', flipped) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 縮放，重新調整大小和 插值\n",
    "    >>Scaling, re-sizing and interpolations\n",
    "       \n",
    "    >> Re-sizing is very easy using the cv2.resize function, it's arguments are\n",
    "    >> cv2.resize(image, dsize(output image size), x scale, y scale, interpolation)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load 加載 圖像 - input image\n",
    "\n",
    "image = cv2.imread('data/input.jpg')\n",
    "\n",
    "#\n",
    "# make 原始大小 圖像 - 3/4 的 圖像\n",
    "\n",
    "image_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\n",
    "cv2.imshow('Scaling - Linear Interpolation', image_scaled) \n",
    "cv2.waitKey()\n",
    "\n",
    "# make 圖像大小 加倍\n",
    "\n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# 設置 精確的 尺寸 來 扭曲重新調整尺寸\n",
    "\n",
    "img_scaled = cv2.resize(image, (900, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled) \n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 圖像金字塔\n",
    "    >> Image Pyramids\n",
    "       \n",
    "    >> 對象檢測 object detection 中 縮放圖像時很有用\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('data/input.jpg')\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original', image )\n",
    "\n",
    "cv2.imshow('Smaller ', smaller )\n",
    "cv2.imshow('Larger ', larger )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 裁剪\n",
    "    >> Cropping\n",
    "       \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('data/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "#  起始像素坐標 pixel coordiantes （裁剪矩形的左上角 cropping rectangle）\n",
    "\n",
    "start_row, start_col = int(height * .25), int(width * .25)\n",
    "\n",
    "# 結束像素坐標 pixel coordiantes（右下角 bottom right）\n",
    "\n",
    "end_row, end_col = int(height * .75), int(width * .75)\n",
    "\n",
    "# 索引 來裁剪 crop 出 我們想要的矩形 rectangle\n",
    "\n",
    "cropped = image[start_row:end_row , start_col:end_col]\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0) \n",
    "cv2.imshow(\"Cropped Image\", cropped) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('data/input.jpg')\n",
    "cv2.imshow('Original', image )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# image = cv2.imread('images1/input.jpg')\n",
    "\n",
    "# Create a matrix of ones,創建一個矩陣 ，然後乘以 175 的 縮放器 \n",
    "# 相同尺寸的圖像的矩陣，其中所有值都是  175\n",
    "M = np.ones(image.shape, dtype = \"uint8\") * 175 \n",
    "\n",
    "# 此矩陣M添加到我們的圖像中\n",
    "# 亮度的增加  increase in brightness\n",
    "\n",
    "added = cv2.add(image, M)\n",
    "cv2.imshow(\"Added\", added)\n",
    "\n",
    "# 同樣也可以減去 -  subtract\n",
    "# 亮度下降 -  brightness\n",
    "\n",
    "\n",
    "subtracted = cv2.subtract(image, M)\n",
    "cv2.imshow(\"Subtracted\", subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 位運算和屏蔽\n",
    "    >> Bitwise Operations and Masking\n",
    "        >> 創建一些簡單的圖像- simple images\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 兩個維度，一個灰度圖像，\n",
    "# 如果做彩色圖像，會使用\n",
    "# rectangle = np.zeros（（300,300,3），np.uint8）\n",
    "\n",
    "\n",
    "\n",
    "# Making a  正方形 - sqare\n",
    "square = np.zeros((300, 300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow(\"Square\", square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Making a 橢圓 - ellipse\n",
    "ellipse = np.zeros((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow(\"Ellipse\", ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 其他 bitwise 操作\n",
    "    >> others bitwise operations\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 僅顯示它們相交的位置\n",
    "\n",
    "\n",
    "And = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow(\"AND\", And)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 顯示正方形或橢圓形的位置\n",
    "\n",
    "bitwiseOr = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow(\"OR\", bitwiseOr)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "\n",
    "# 顯示其中任何一個存在的位置\n",
    "\n",
    "bitwiseXor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow(\"XOR\", bitwiseXor)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 一切都不是 正方形 的一部分\n",
    "\n",
    "bitwiseNot_sq = cv2.bitwise_not(square)\n",
    "cv2.imshow(\"NOT - square\", bitwiseNot_sq)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 最後一次操作完全反轉了圖像\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 卷積 和 模糊 操作\n",
    "    >> Convolutions and Blurring\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('data/elephant.jpg')\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 創造 3 x 3 kernel\n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "# cv2.filter2D  內核與圖像卷積 - 在一起\n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 創造 7 x 7 kernel\n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('data/elephant.jpg')\n",
    "\n",
    "# 通過將圖像與標準化的 filter 進行卷積來完成平均\n",
    "# 獲取框下 filter  的像素並替換中心元素\n",
    "# filter  size 大小需要奇數和正數 -  odd and positive \n",
    "\n",
    "\n",
    "blur = cv2.blur(image, (3,3))\n",
    "cv2.imshow('Averaging', blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# filter, 高斯內核 - gaussian kernel \n",
    "Gaussian = cv2.GaussianBlur(image, (7,7), 0)\n",
    "cv2.imshow('Gaussian Blurring', Gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 取內核區域和中心區域內所有像素的中位數\n",
    "# E lement被這個中值替換\n",
    "\n",
    "median = cv2.medianBlur(image, 5)\n",
    "cv2.imshow('Median Blurring', median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Bilateral 雙邊 非常有效地去除噪音，同時保持邊緣清晰\n",
    "\n",
    "bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "cv2.imshow('Bilateral Blurring', bilateral)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('data/elephant.jpg')\n",
    "\n",
    "# None之後的參數 - 過濾器強度 ' h' (5-10是一個很好的範圍 )\n",
    "# Nex t是 hForColorComponents， 再次設置為與 h相同的值\n",
    " \n",
    "\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21)\n",
    "\n",
    "cv2.imshow('Fast Means Denoising', dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 4 variations of  非 本地均值去噪的變化 - Non-Local Means Denoising:**\n",
    "\n",
    "- cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "- cv2.fastNlMeansDenoisingColored() - works with a color image.\n",
    "- cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images)\n",
    "- cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 等高線 輪廓\n",
    "    >> Contours\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load 加載一個帶有3個黑色方塊的簡單圖像\n",
    "\n",
    "\n",
    "image = cv2.imread('data/shapes.jpg')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 灰度 - Grayscale\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges - Canny 邊緣\n",
    "\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# 查找輪廓\n",
    "# 使用 圖片副本，例如 edged.copy（），因為 會findContours 改變了 圖像\n",
    "\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# 繪製所有輪廓\n",
    "# -1 作為第三個參數來繪製所有\n",
    "\n",
    "\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.findContours(image, Retrieval Mode, Approximation Method)**\n",
    "\n",
    "Returns -> contours, hierarchy\n",
    "\n",
    "**OpenCV 3.X 中，findContours返回第三個參數ret（或一個布爾值，表示函數是否成功運行）。\n",
    "\n",
    "如果您使用的是OpenCV 3.X，請將第12行替換為：\n",
    "\n",
    "_，contours，hierarchy = cv2.findContours（image，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_NONE）\n",
    "\n",
    "變量'contours'存儲為形成輪廓的（x，y）點的numpy數組\n",
    "\n",
    "而“ hierarchy ”描述了輪廓之間的子母關係（即輪廓內的輪廓）\n",
    "\n",
    "\n",
    "#### 其他 方法\n",
    "\n",
    "使用cv2.CHAIN_APPROX_NONE 存儲所有邊界點 , 但我們並不一定需要所有的邊界點 , 如果點形成一條直線，我們只需要該線的起點和終點。\n",
    "\n",
    "使用cv2.CHAIN_APPROX_SIMPLE 只能提供邊界輪廓的這些起點和終點, 從而更有效地存儲輪廓信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found =  121\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load 加載 圖片 \n",
    "image = cv2.imread('data/GeneralMethod.jpg')\n",
    "cv2.imshow('0 - Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 創建 與 加載的圖像 具有相同尺寸的黑色圖像\n",
    "\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "# 創建 原始圖像的 副本\n",
    "orginal_image = image\n",
    "\n",
    "# image 灰度Grayscale \n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny 邊緣\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('1 - Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 查找 輪廓並 PRINT OUT 發現的數量\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print (\"Number of contours found = \", len(contours))\n",
    "\n",
    "# 繪製所有 輪廓  contours\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('2 - All Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Draw 在空白圖像上 繪製 所有輪廓 \n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('3 - All Contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 按地區排序\n",
    "    >> sort by area\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contor Areas before sorting\n",
      "[11.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.5, 0.5, 23.0, 9.0, 1.5, 4.5, 6.0, 11.0, 2.0, 3.5, 216.5, 151.5, 150.0, 174.0, 139.5, 117.0, 27.5, 265.5, 8.0, 5.5, 15.5, 3.5, 4.5, 16.0, 11.0, 6.0, 29.5, 397.0, 281.5, 400.0, 179.0, 273.5, 396.0, 248.0, 399.5, 277.5, 247.0, 15.5, 386.0, 285.0, 250.5, 9.0, 4.5, 401.0, 395.5, 53.0, 9.0, 272.0, 256.5, 12.5, 22.0, 538.0, 15.0, 150.0, 150.5, 140.5, 17.5, 12.0, 3.0, 18.0, 146.5, 18.0, 16.0, 425.5, 25.0, 22.0, 12.0, 5.0, 205.0, 14.0, 9.5, 6.0, 18.5, 378.5, 533.5, 107.0, 327.5, 47.5, 20.5, 14.0, 0.5, 54.0, 13.5, 11.5, 206.0, 87.5, 13.0, 222.5, 3.0, 16.0, 0.0, 0.0, 18.0, 103.0, 20.5, 319.5, 41.5, 74908.5, 0.0, 0.0, 0.0, 43.5, 85.5, 71.5, 82.5, 75.0, 254.0, 306.0, 0.0, 85186.5, 54.5]\n",
      "Contor Areas after sorting\n",
      "[85186.5, 74908.5, 538.0, 533.5, 425.5, 401.0, 400.0, 399.5, 397.0, 396.0, 395.5, 386.0, 378.5, 327.5, 319.5, 306.0, 285.0, 281.5, 277.5, 273.5, 272.0, 265.5, 256.5, 254.0, 250.5, 248.0, 247.0, 222.5, 216.5, 206.0, 205.0, 179.0, 174.0, 151.5, 150.5, 150.0, 150.0, 146.5, 140.5, 139.5, 117.0, 107.0, 103.0, 87.5, 85.5, 82.5, 75.0, 71.5, 54.5, 54.0, 53.5, 53.0, 47.5, 43.5, 41.5, 29.5, 27.5, 25.0, 23.0, 22.0, 22.0, 20.5, 20.5, 18.5, 18.0, 18.0, 18.0, 17.5, 16.0, 16.0, 16.0, 15.5, 15.5, 15.0, 14.0, 14.0, 13.5, 13.0, 12.5, 12.0, 12.0, 11.5, 11.5, 11.0, 11.0, 9.5, 9.0, 9.0, 9.0, 8.0, 6.0, 6.0, 6.0, 5.5, 5.0, 4.5, 4.5, 4.5, 3.5, 3.5, 3.0, 3.0, 2.0, 1.5, 1.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 將用於顯示輪廓區域的功能\n",
    "\n",
    "def get_contour_areas(contours):\n",
    "\n",
    "    # returns 返回所有輪廓的區域作為列表 \n",
    "    \n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "# Load 加載 圖片 \n",
    "\n",
    "image = cv2.imread('data/GeneralMethod.jpg') # bunchofshapes.jpg\n",
    "orginal_image = image\n",
    "\n",
    "# print 排序之前 print 輪廓區域\n",
    "print (\"Contor Areas before sorting\",) \n",
    "print (get_contour_areas(contours))\n",
    "\n",
    "# Sort contours 從大到小排序 輪廓 \n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "#sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
    "\n",
    "print (\"Contor Areas after sorting\",) \n",
    "print (get_contour_areas(sorted_contours))\n",
    "\n",
    "# Iterate over 輪廓 - 並一次繪製一個\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(orginal_image, [c], -1, (255,0,0), 3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by area', orginal_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found =  4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load 加載 圖片 \n",
    "image = cv2.imread('data/bunchofshapes.jpg')\n",
    "cv2.imshow('0 - Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 創建 與 加載的圖像 具有相同尺寸的黑色圖像\n",
    "\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "# 創建 原始圖像的 副本\n",
    "orginal_image = image\n",
    "\n",
    "# image 灰度Grayscale \n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny 邊緣\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('1 - Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 查找 輪廓並 PRINT OUT 發現的數量\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print (\"Number of contours found = \", len(contours))\n",
    "\n",
    "# 繪製所有 輪廓  contours\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('2 - All Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Draw 在空白圖像上 繪製 所有輪廓 \n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('3 - All Contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images1\\output_shape_number_1.jpg\n",
      "images1\\output_shape_number_2.jpg\n",
      "images1\\output_shape_number_3.jpg\n",
      "images1\\output_shape_number_4.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Functions - 按位置排序的函數\n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    # 返回輪廓contour centroid 的X坐標 centroid\n",
    "    \n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "\n",
    "    \n",
    "def label_contour_center(image, c):\n",
    "    # 輪廓中心放置一個 紅色圓圈\n",
    "    \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    " \n",
    "    # Draw 在圖像上繪製輪廓編號\n",
    "    \n",
    "    cv2.circle(image,(cx,cy), 10, (0,0,255), -1)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Load 加載 圖片 \n",
    "image = cv2.imread('data/bunchofshapes.jpg')\n",
    "orginal_image = image.copy()\n",
    "\n",
    "\n",
    "#  Center of Mass or centroids 中心並在我們的圖像上 繪製它們  \n",
    "\n",
    "for (i, c) in enumerate(contours):\n",
    "    orig = label_contour_center(image, c)\n",
    " \n",
    "cv2.imshow(\"4 - Contour Centers \", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Sort 使用我們的x_cord_contour函數 - 從左到右排序 \n",
    "\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n",
    "\n",
    "\n",
    "# Labeling Contours 從左到右標記輪廓 \n",
    "\n",
    "for (i,c)  in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(orginal_image, [c], -1, (0,0,255), 3)  \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    cv2.putText(orginal_image, str(i+1), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('6 - Left to Right Contour', orginal_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)  \n",
    "    \n",
    "    # crop 裁剪 每個輪廓並保存這些圖像\n",
    "    \n",
    "    cropped_contour = orginal_image[y:y + h, x:x + w]\n",
    "    image_name = \"images1\\output_shape_number_\" + str(i+1) + \".jpg\"\n",
    "    print (image_name)\n",
    "    cv2.imwrite(image_name, cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 近似等高線- Contours and Convex Hull 凸殼\n",
    "\n",
    "***cv2.approxPolyDP(contour, Approximation Accuracy, Closed)***\n",
    "- **contour** – 希望 近似的 單個輪廓\n",
    "- **Approximation Accuracy** – 重要參數是確定近似的準確性。 小值給出精確近似值，大值給出更一般的近似值。 一個好的經驗法則是小於輪廓周長的5％\n",
    "- **Closed** – a Boolean value - 一個布爾值，指出近似輪廓是打開還是關閉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load 加載圖像 , 保留副本\n",
    "\n",
    "image = cv2.imread('data/house.jpg')\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Grayscale 灰度 和 二值化  binarize\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# 查找輪廓 contours \n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate 每個輪廓, 計算邊界矩形 bounding rectangle\n",
    "\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)    \n",
    "    cv2.imshow('Bounding Rectangle', orig_image)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "    \n",
    "# Iterate 迭代每個輪廓, 計算近似輪廓\n",
    "\n",
    "for c in contours:\n",
    "    # Calculate 計算 輪廓周長的 百分比\n",
    "\n",
    "    accuracy = 0.03 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, accuracy, True)\n",
    "    cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Approx Poly DP', image)\n",
    "    \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Convex Hull \n",
    "    >> 凸包或凸包絡或凸閉合一組X點在歐幾里得平面或在歐氏空間（或者，更一般地，在一個仿射空間在實數）是最小的凸集包含X\n",
    "    >> https://en.wikipedia.org/wiki/Convex_hull\n",
    "    \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('data/hand.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Threshold 閾值 圖像\n",
    "\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "# 查找 輪廓 contours \n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    \n",
    "# Sort Contors 按區域對輪廓 進行排序，然後 刪除最大的 框架輪廓\n",
    "\n",
    "n = len(contours) - 1\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=False)[:n]\n",
    "\n",
    "# Iterate 輪廓迭代 , 繪製凸包\n",
    "\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 步驟 2 ：特徵提取\n",
    "    >> Step 2 : Feature Extraction\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 輸入圖像input image 具有太多額外信息，這些信息對於分類不是必需的\n",
    "    >> 因此，\n",
    "    >> 圖像分類 image classification\n",
    "        >> 第一步是\n",
    "            >> 通過提取圖像中包含的重要信息\n",
    "                >> extracting the important informatio\n",
    "            >> 並將其餘部分省略來簡化圖像\n",
    "        >> 例如\n",
    "            >> 如果要在圖像中\n",
    "                >> 找到襯衫 shirt 和外套按鈕 coat buttons\n",
    "                    >> 會注意到RGB\n",
    "                        >> 像素值 RGB pixel values的顯著變化\n",
    "            >> 但是，通過在圖像上運行邊緣檢測器 edge detector  \n",
    "                >> 可以簡化圖像\n",
    "                >> 仍然可以輕鬆地辨別這些邊緣圖像 edge images 中\n",
    "                    >> 按鈕的圓形形狀 circular shape\n",
    "                >> 因此可以得出結論\n",
    "                    >> 邊緣檢測 edge detection保留了基本信息\n",
    "                    >> 同時丟棄了非必要信息\n",
    "         >> 該步驟稱為特徵提取 feature extraction\n",
    "         \n",
    "         \n",
    "    >> 在傳統的計算機視覺方法中 Traditional Computer Vision \n",
    "        >> 設計這些特徵 features\n",
    "            >> 對於算法 algorithm的性能是至關重要的\n",
    "        \n",
    "        >> 事實證明\n",
    "            >> 可以比簡單的邊緣檢測 simple edge detection 做得更好\n",
    "                >> 並找到更可靠的功能\n",
    "        >> 在襯衫 shirt 和外套按鈕 coat buttons 示例中\n",
    "            >> 一個好的特徵檢測器不僅可以捕獲按鈕的圓形形狀\n",
    "            >> 還可以獲取\n",
    "               >> 有關按鈕與其他圓形物體（如汽車輪胎）的不同之處的信息\n",
    "\n",
    "    >> 計算機視覺中\n",
    "        >> 使用的一些眾所周知的特徵是由 Viola 和 Jones\n",
    "          >> Histogram of Oriented Gradients ( HOG )  特徵\n",
    "          >> Scale-Invariant Feature Transform SIFT 尺度不變特徵變換\n",
    "          >> 加速魯棒特徵（Speeded Up Robust Feature ( SURF )\n",
    "          \n",
    "'''                            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 直方圖梯度圖 / 定向梯度直方圖 (HOG)\n",
    "    >> Histogram of Oriented Gradients ( HOG )\n",
    "        >> 進行特徵提取 feature extraction algorithm \n",
    "\n",
    "    >> 定向梯度直方圖（HOG）\n",
    "        >> 特徵提取算法 Feature Extraction Algorithm\n",
    "        >> 將固定大小的圖像轉換為固定大小的特徵向量\n",
    "            >> image of fixed size to a feature vector of fixed size.\n",
    "        >> 在行人檢測 Pedestrian Detection 的情況下\n",
    "            >> HOG 特徵描述符 HOG feature descriptor\n",
    "                >> 是針對圖像的64×128補丁計算的\n",
    "                    >> 並返回大小為3780的向量 vector\n",
    "                >> 請注意\n",
    "                >> 此圖像原始尺寸為64 x 128 x 3 = 24,576\n",
    "                >> 這是HOG描述符 descriptor\n",
    "                    >> 減少到3780\n",
    "\n",
    "        >> HOG \n",
    "            >> 基於這樣的思想 Local Object Appearance\n",
    "            >> 可以通過邊緣方向(local object appearance 定向梯度)\n",
    "                >> 的分佈 distribution(histogram 直方圖)\n",
    "                >> 有效地描述局部對像外觀\n",
    "                \n",
    "                \n",
    "        >> 下面\n",
    "            >> 計算64×128圖像\n",
    "                >> HOG描述符的步驟\n",
    "\n",
    "           \n",
    "'''                    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 梯度計算 Gradient calculation：\n",
    "    >> 計算在 x梯度  gradient 和 y梯度 gradient 的圖像\n",
    "        >> g_x 並且 G_Y，從所述原始圖像 original image\n",
    "        >> 這可以通過\n",
    "        >> 使用以下內核過濾原始圖像 filtering the original image\n",
    "            >> 來完成\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2016/11/gradient-kernels.jpg\" width=\"25%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 使用梯度 圖像 \n",
    "    >> Gradient images G_x 和 G_Y\n",
    "    >> 計算出\n",
    "        >> 使用下列公式梯度 equations 的 幅度 magnitude  \n",
    "        >> orientation of the gradient 方向。\n",
    "\n",
    "    >> calcuated gradients\n",
    "    >> 計算的梯度是“ 無符號的 unsigned ”\n",
    "        >> 因此\\ THETA\n",
    "            >> 在 0到180度的範圍內\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.learnopencv.com/wp-content/ql-cache/quicklatex.com-63f6cd0dabced613d560b807221f8527_l3.png\" width=\"25%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 細胞 Cells\n",
    "    >> 將圖像分成8×8個細胞。\n",
    "    >> 計算這些8×8細胞中梯度的直方圖 \n",
    "        >> Calculate histogram of gradients in these 8×8 cells\n",
    "        >> 在8×8單元中的每個像素處\n",
    "            >> 知道梯度（幅度和方向）\n",
    "                >> 因此有64個幅度和64個方向 - 即128個數字\n",
    "            >> 這些梯度的直方圖將提供更有用和緊湊的表示\n",
    "    >> 接下來，我們將這128個數字轉換為9個bin的直方圖（即9個數字）\n",
    "    \n",
    "    >> 直方圖的區間\n",
    "        >> 對應於梯度方向0,20,40 ...... 160度\n",
    "        >> 每個像素\n",
    "            >> 在直方圖中投票給一個或兩個二進制位\n",
    "        >> 如果像素處的梯度的方向恰好是0度，20度，40度或160度\n",
    "            >> 則將像素投射到像素中的投票等於梯度的大小\n",
    "        >> 一個像素\n",
    "            >> 其中漸變的方向不完全是0,20,40 ...... 160度\n",
    "            >> 基於距離箱的距離在兩個最近的箱中分割其投票\n",
    "    >> 例如\n",
    "        >> 塊標準化 Block normalization\n",
    "        >> 在上一步驟中計算的直方圖對照明變化不是很穩健\n",
    "        >> 通過常數因子乘以圖像強度也可以縮放直方圖箱值\n",
    "        >> 為了對抗這些影響\n",
    "            >> 可以對直方圖進行歸一化 \n",
    "            >> 即將直方圖視為9個元素的向量\n",
    "            >> 並將每個元素除以該向量的大小\n",
    "        >> 在原始的HOG論文中\n",
    "            >> 這種歸一化不是在產生直方圖的8×8單元上進行的\n",
    "            >> 而是在16×16塊上進行\n",
    "            \n",
    "        >> 這個想法是一樣的\n",
    "            >> 但現在不是9元素矢量，而是36元素向量\n",
    "            \n",
    "            \n",
    "    >> 特徵向量 Feature Vector\n",
    "        >> 在前面的步驟中\n",
    "            >> 想出瞭如何在8×8單元上計算直方圖\n",
    "                >> 然後在16×16塊上對其進行歸一化\n",
    "            >> 為了計算整個圖像的最終特徵向量 final vector\n",
    "            >> 16×16塊\n",
    "                >> 以8的步長移動（即與前一個塊重疊50％）\n",
    "                >> 和36個數字（對應於16×16塊中的4個直方圖）\n",
    "            >> 在連接每個步驟以產生最終的特徵向量\n",
    "         \n",
    "        >>最終載體的長度是多少\n",
    "            >> What is the length of the final vector\n",
    "            >> 輸入圖像的大小為64×128像素\n",
    "                >> 一次移動8個像素\n",
    "            >> 因此\n",
    "                >> 可以在水平方向上製作7個步驟\n",
    "                >> 在垂直方向上製作15個步驟\n",
    "                    >> 這相當於7 x 15 = 105步\n",
    "                >> 在每一步\n",
    "                    >> 計算了36個數字\n",
    "                    >> 這使得最終向量\n",
    "                        >> 長度為105×36 = 3780\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 步驟 2 ：學習分類算法\n",
    "    >> Step 2 : Learning Algorithm For Classification\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "\n",
    ">> 上面了解\n",
    "    >> 如何將\n",
    "        >> 圖像 Image轉換為特徵向量 Feature Vector\n",
    "    >> 將學習分類算法 background\n",
    "        >> 將此特徵向量 feature vector\n",
    "            >> 作為輸入並輸出類標籤 Class Label\n",
    "            >> 例如 - 貓 cat 或背景 background\n",
    "\n",
    "    >> 分類算法 Classification Algorithm 之前\n",
    "        >> 需要通過展示成千上萬的貓和背景\n",
    "            >> 示例來訓練它\n",
    "        >> 不同的學習算法學習方法不同\n",
    "        >> 但一般原則\n",
    "            >> 是學習算法\n",
    "                >> 將特徵向量 higher dimensional \n",
    "                    >> 視為高維空間中的點\n",
    "            >> 並嘗試\n",
    "                >> 找到分割高維空間的平面/表面 planes / surfaces\n",
    "            >> 使得屬於同一類\n",
    "                >> 所有示例都是在plane / surface的一側。\n",
    "\n",
    "    >> 支持向量機 Support Vector Machine ( SVM )\n",
    "        >> 稱為支持向量機（Support Vector Machines ( SVM )的學習算法。\n",
    "\n",
    "        >> 支持向量機（SVM）如何用於圖像分類？\n",
    "        >> 支持向量機（SVM）是最受歡迎的監督二進制分類算法之一\n",
    "        >> 雖然SVM中使用\n",
    "            >> 自1963年以來一直存在\n",
    "        >> 當前的版本\n",
    "            >> 是由 Cortes 和 Vapnik\n",
    "                >> 1995年提出的\n",
    "\n",
    "    >> 了解到圖像的 HOG描述符 descriptor\n",
    "        >> 是長度為3780的特徵向量\n",
    "            >> 可以將此向量看作3780維空間中的點\n",
    "            >> 可視化更高維度的空間是不可能的\n",
    "            >> 所以讓我們稍微簡化一下\n",
    "            >> 並想像\n",
    "                >> 特徵向量只是二維的\n",
    "                \n",
    " '''               "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "\n",
    ">> 上面了解\n",
    "    >> 如何將\n",
    "        >> 圖像 Image轉換為特徵向量 Feature Vector\n",
    "    >> 將學習分類算法 background\n",
    "        >> 將此特徵向量 feature vector\n",
    "            >> 作為輸入並輸出類標籤 Class Label\n",
    "            >> 例如 - 貓 cat 或背景 background\n",
    "\n",
    "    >> 分類算法 Classification Algorithm 之前\n",
    "        >> 需要通過展示成千上萬的貓和背景\n",
    "            >> 示例來訓練它\n",
    "        >> 不同的學習算法學習方法不同\n",
    "        >> 但一般原則\n",
    "            >> 是學習算法\n",
    "                >> 將特徵向量 higher dimensional \n",
    "                    >> 視為高維空間中的點\n",
    "            >> 並嘗試\n",
    "                >> 找到分割高維空間的平面/表面 planes / surfaces\n",
    "            >> 使得屬於同一類\n",
    "                >> 所有示例都是在plane / surface的一側。\n",
    "\n",
    "    >> 支持向量機 Support Vector Machine ( SVM )\n",
    "        >> 稱為支持向量機（Support Vector Machines ( SVM )的學習算法。\n",
    "\n",
    "        >> 支持向量機（SVM）如何用於圖像分類？\n",
    "        >> 支持向量機（SVM）是最受歡迎的監督二進制分類算法之一\n",
    "        >> 雖然SVM中使用\n",
    "            >> 自1963年以來一直存在\n",
    "        >> 當前的版本\n",
    "            >> 是由 Cortes 和 Vapnik\n",
    "                >> 1995年提出的\n",
    "\n",
    "    >> 了解到圖像的 HOG描述符 descriptor\n",
    "        >> 是長度為3780的特徵向量\n",
    "            >> 可以將此向量看作3780維空間中的點\n",
    "            >> 可視化更高維度的空間是不可能的\n",
    "            >> 所以讓我們稍微簡化一下\n",
    "            >> 並想像\n",
    "                >> 特徵向量只是二維的\n",
    "                \n",
    " '''               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load 加載 灰度圖像 - gray scale image\n",
    "\n",
    "image = cv2.imread('data/someshapes.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Identifying Shapes',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 1)\n",
    "\n",
    "# 提取輪廓\n",
    "# Extract Contours\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    # 獲取 近似 多邊形\n",
    "    # Get approximate polygons\n",
    "    \n",
    "    approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt,True),True)\n",
    "    \n",
    "    if len(approx) == 3:\n",
    "        shape_name = \"Triangle\"\n",
    "        cv2.drawContours(image,[cnt],0,(0,255,0),-1)\n",
    "        \n",
    "        # 找到輪廓中心 - 將文字放在中心 \n",
    "        # Find contour center to place text at the center\n",
    "        \n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    \n",
    "    elif len(approx) == 4:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        \n",
    "        # 檢查4面多邊形是 方形還是矩形  - square or rectangle\n",
    "        # cv2.boundingRect  - 返回左上角 然後 返回寬度 \n",
    "        \n",
    "        \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = \"Square\"\n",
    "            \n",
    "            # 找到輪廓中心 - 將文字放在中心 \n",
    "            # Find contour center to place text at the center\n",
    "            \n",
    "            \n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125 ,255), -1)\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        else:\n",
    "            shape_name = \"Rectangle\"\n",
    "            \n",
    "            # 找到輪廓中心 - 將文字放在中心 \n",
    "            # Find contour center to place text at the center\n",
    "            \n",
    "            cv2.drawContours(image, [cnt], 0, (0, 0, 255), -1)\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "            \n",
    "    elif len(approx) == 10:\n",
    "        shape_name = \"Star\"\n",
    "        cv2.drawContours(image, [cnt], 0, (255, 255, 0), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif len(approx) >= 15:\n",
    "        shape_name = \"Circle\"\n",
    "        cv2.drawContours(image, [cnt], 0, (0, 255, 255), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "    cv2.imshow('Identifying Shapes',image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
